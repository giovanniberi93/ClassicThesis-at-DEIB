% !TEX root = ../ClassicThesis_DEIB.tex

\chapter{Conclusions} \label{chap:conclusions}

In this work we designed, developed and validated the software components of an autonomous mobile manipulator. The system is equipped with an odometry system that robustly provides an accurate estimation of the robot geolocalized pose and orientation, exploiting data from GPS, IMU, and wheels velocities. The pose estimation is used by the platform to achieve autonomous navigation on steep, rough, and very bumpy terrain and, by means of a single-plane frontal \ac{LIDAR}, the vehicle is able to deal with irregular obstacles such as the vines trunks and other accidental vegetation (\textit{e.g.} high weeds) in the vineyard.
\ac{AMCL} localization algorithm was not able to deal with the high degree of repetitiveness of the vineyard map, so we opted for the substitution of the global map with an handcrafted  \textit{prohibition layer} to represent the vineyard rows as obstacles. Even if this operation has to be made by hand, we consider it more efficient solution than the map usage because:
\begin{itemize}
	\item the vineyard rows are very simple and regular obstacles to be specified by hand, since they are identified by only two geolocalized endpoints each; thus, GPS coordinates of endpoints can also be extracted via satellite imagery
	\item the \textit{prohibition layer} specification is easier and faster than traditional mapping phase, and in our case fully substitutes it
	\item the inclusion of \textit{prohibition layers} in both local and global costmaps avoids row crossing problem
\end{itemize}
The main goal of \ac{GRAPE} project, the automatic deployment of pheromones dispensers in the vineyard, is executed by means of the on-board manipulator, and validated via computer vision techniques designed to detect the expressly-placed dispenser's red wings in the image frame.
We designed two different execution modes for the dispenser deployment operation:
\begin{enumerate}
	\item application of the dispenser in a point output by the processing of a 3D reconstruction of the target vine
	\item application of the dispenser on a target nail, via visual servoing control with the help of specifically placed binary fiducial markers 
\end{enumerate}
These solutions can be selected according to the willingness of the wine growers not to modify the vineyard structure at all (solution 1), or to carry out a simple preparation of the vineyard in order to enjoy an easier and more robust dispenser deployment procedure (solution 2).

After two \textit{on-the-field} sessions, we can certify the robustness of sensor fusion, localization, and manipulation systems in the actual vineyard environment. However, we were also able to identify some weaknesses in the resulting platform, that could be addressed in future work:
\begin{itemize}
	\item during the system development, no particular emphasis to the power consumption problem was given; thus, the current power supply system of the Husky can support the platform for about 4 hours. Even if the change of batteries is a simple and fast operation, it's carried out by humans and it largely decreases the platform potential. A power-aware restyling of both software and hardware components of the system would be one of the main improvements of the platform
	\item the sensor fusion system strongly relies on high-precision GPS, that actually is not available worldwide. Navigation system is the component that would mainly suffer from faulty localization, so a possible solution to disengage it in some measure from high-precision GPS would be to introduce a (maybe partially) image-driven navigation system, that exploits the regularity of vine rows to select the navigation direction
	\item even if we had difficulties to include \ac{AMCL} algorithm in the final sensor fusion system (see Section \ref{subsec:AMCLinSensorFusion}), we think that a successful inclusion could be very useful for the development of a sensor fusion algorithm that, given the well known potential of \ac{AMCL} in indoor localization, could effectively estimate the robot pose both in indoor and outdoor environment.
	\item the computer vision operations that do not rely on binary fiducial markers (\textit{i.e.} validation of grasping and deployment of the dispenser, detection of dispenser availability in the feeder) turned out to be weaker then expected when executed in strong and direct sunlight conditions, but for mere lack of time we could not directly address this problem. A more fine-grained configuration of the procedures might be sufficient to significantly improve their performance.
\end{itemize}





